language: python

python:
  - 3.5

services:
  - postgresql

addons:
  postgresql: "9.5"
  apt:
    packages:
      - postgresql-9.5-postgis-2.3

cache:
  - $HOME/.cache/pip
  - $HOME/public

git:
  depth: 3

env:
  global:
    - PG_DATABASE=postgres
    - DATE=2017-05-19
    - INFERNOFLAGS=--quiet

  matrix:
    - TASK=routeratio
    - TASK=spacing
    - TASK=evt
    - TASK=prepare cewt
    - TASK=otp
    - TASK=otd
    - TASK=prepare bunching
    - TASK=service
    - TASK=speed
    - TASK=prepare wtp

before_install:
  - psql --version
  - git clone --depth 3 https://github.com/fitnr/gtfs-sql-importer.git
  - git clone --depth 3 https://github.com/Bus-Data-NYC/mta-bus-archive.git
  - git clone --depth 3 https://github.com/Bus-Data-NYC/inferno.git
  - git clone https://gist.github.com/be056c2342e115c37e97d73719417bea.git gtfs

install:
  - make -e init drop_constraints -C gtfs-sql-importer
  - pip install -r mta-bus-archive/requirements.txt
  - while read line; do ls ${line##http*.com/} || curl --create-dirs -o ${line##htt*com/} $line; done < gtfs/feeds.txt
  - find $HOME/public -name '*.zip' -exec make -e load gtfs-sql-importer GTFS={} \;
  - make -e init csv xz/bus_time_${DATE//-/}.csv.xz -C mta-bus-archive
  # Limit the number of positions to speed up tests
  - xz -d --stdout mta-bus-archive/xz/bus_time_${DATE//-/}.csv.xz | head -n 100000 > mta-bus-archive/csv/bus_time_${DATE//-/}.csv
  - make -e download -C mta-bus-archive
  - make -e init calls-day-${DATE} -C inferno
  - make -e init MONTH=2017-05

before_script:
  - psql $PG_DATABASE -c "select postgis_full_version()"

script: make -e $TASK
